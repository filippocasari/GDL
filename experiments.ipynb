{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "import pytorch_lightning.loggers\n",
    "\n",
    "import torch\n",
    "import aegnn\n",
    "from aegnn.models.networks import GraphRes\n",
    "from scripts.train import LearningRateLogger\n",
    "from aegnn.models.utils.map import compute_map\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "\n",
    "#ncars alredy split\n",
    "#https://drive.google.com/file/d/1vlByGVjqmyYvbzLSIzZzNLfcjfTJijyz/view\n",
    "\n",
    "\n",
    "#save data in raw and make dirs train,validation,test\n",
    "\n",
    "split=False\n",
    "\n",
    "if(split):\n",
    "    ### Copy the data into the train, validation and test directories (80%, 10%, 10%)\n",
    "    dataset='ncaltech101'\n",
    "\n",
    "    original_dir= os.getcwd()+'/data/'+dataset\n",
    "    train_dir= original_dir +'/training'\n",
    "    val_dir= original_dir +'/validation'\n",
    "    test_dir= original_dir +'/test'\n",
    "\n",
    "    original_dir+='/raw'\n",
    "\n",
    "    ### Make a directory for each class in the train, validation, test directories.\n",
    "\n",
    "    class_counts = {}\n",
    "\n",
    "    class_folders = os.listdir(original_dir)\n",
    "\n",
    "    for class_dir in class_folders:\n",
    "        os.mkdir(os.path.join(train_dir, class_dir))\n",
    "        os.mkdir(os.path.join(val_dir, class_dir))\n",
    "        os.mkdir(os.path.join(test_dir, class_dir))\n",
    "        \n",
    "        class_counts[class_dir] = len(os.listdir(os.path.join(original_dir, class_dir)))\n",
    "\n",
    "    print (class_counts)\n",
    "\n",
    "    for class_dir in class_folders:\n",
    "        images = os.listdir(os.path.join(original_dir, class_dir))\n",
    "        random.seed(42)\n",
    "        random.shuffle(images)\n",
    "\n",
    "        train_images = images[:int(0.8 * class_counts[class_dir])]\n",
    "        val_images = images[int(0.8 * class_counts[class_dir]):int(0.9 * class_counts[class_dir])]\n",
    "        test_images = images[int(0.9 * class_counts[class_dir]):]\n",
    "\n",
    "        for image in train_images:\n",
    "            shutil.copyfile(os.path.join(original_dir, class_dir, image), os.path.join(train_dir, class_dir, image))\n",
    "\n",
    "        for image in val_images:\n",
    "            shutil.copyfile(os.path.join(original_dir, class_dir, image), os.path.join(val_dir, class_dir, image))\n",
    "\n",
    "        for image in test_images:\n",
    "            shutil.copyfile(os.path.join(original_dir, class_dir, image), os.path.join(test_dir, class_dir, image))\n",
    "\n",
    "### Check that the data has been split correctly\n",
    "for split in [train_dir, val_dir, test_dir]:\n",
    "    total = 0\n",
    "    for class_dir in os.listdir(split):\n",
    "        total += len(os.listdir(os.path.join(split, class_dir)))\n",
    "    print(split, total)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!CUDA_VISIBLE_DEVICES=0 AEGNN_DATA_DIR=$(pwd)/data python scripts/preprocessing.py --dataset \"ncars\" --num-workers 8 --gpu 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python evaluation/accuracy_per_events.py ~/home/ale/Downloads/GDL/data/log/checkpoints/ncars/recognition/20230504003225/epoch=49-step=5099.pt --device cuda --dataset ncars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "model_name = \"ncaltech101\" #ncars\n",
    "#model_name = \"ncars\"\n",
    "file_path = f'/home/ale/Downloads/aegnn_results/accuracy_per_events_{model_name}.pkl'\n",
    "\n",
    "with open(file_path, 'rb') as file:\n",
    "    flops_data = pickle.load(file)\n",
    "flops_df = pd.DataFrame(flops_data)\n",
    "save_to_excel = True\n",
    "if save_to_excel == True:    \n",
    "    # Specify the output file path\n",
    "    output_file_path = f'/home/ale/Downloads/aegnn_results/accuracy_per_events_{model_name}.xlsx'\n",
    "\n",
    "    # Save the DataFrame to the Excel file\n",
    "    flops_df.to_excel(output_file_path, index=False, engine='openpyxl')\n",
    "    flops_df.info()\n",
    "    x = flops_df[\"max_num_events\"]\n",
    "    y = flops_df[\"accuracy\"]\n",
    "    plt.plot(x, y)\n",
    "    plt.xlabel(\"Number of Events\")\n",
    "    plt.ylabel(\"Recognition Accuracy\")\n",
    "    plt.title(f\"Dataset: {model_name}\")\n",
    "    plt.grid()\n",
    "    plt.savefig(f'/home/ale/Downloads/aegnn_results/accuracy_per_events_{model_name}.png')\n",
    "    plt.show()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "file_path = '../aegnn_results/flops.pkl'\n",
    "\n",
    "with open(file_path, 'rb') as file:\n",
    "    flops_data = pickle.load(file)\n",
    "\n",
    "\n",
    "flops_df = pd.DataFrame(flops_data)\n",
    "\n",
    "\n",
    "# TODO: set save_to_excel = True if you run this block the first time \n",
    "save_to_excel = False\n",
    "if save_to_excel == True:    \n",
    "    # Specify the output file path\n",
    "    output_file_path = 'results/flops_data_ncars.xlsx'\n",
    "\n",
    "    # Save the DataFrame to the Excel file\n",
    "    flops_df.to_excel(output_file_path, index=False, engine='openpyxl')\n",
    "\n",
    "flops_df['Mflops/ev'] = flops_df['flops'] / 1e6 / 10000\n",
    "\n",
    "total_df=flops_df[flops_df['layer'] == 'total']\n",
    "print(total_df['layer'].value_counts()['total'])\n",
    "total_df_dense = total_df[total_df['model'] == 'gnn_dense'].dropna(subset=['flops'])\n",
    "total_df_ours = total_df[total_df['model'] == 'ours'].dropna(subset=['flops'])\n",
    "\n",
    "\n",
    "\n",
    "average_total_dense= total_df_dense['flops'].sum()/1e6/10000\n",
    "average_total_ours= total_df_ours['flops'].sum()/1e6/10000\n",
    "\n",
    "\n",
    "print(average_total_dense)\n",
    "print(average_total_ours)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aegnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
